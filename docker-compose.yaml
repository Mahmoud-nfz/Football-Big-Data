services:
  spark:
    profiles:
      - main
    image: apache/spark-py
    volumes:
      - .:/opt/spark/work-dir/mount
  kafka-broker:
    profiles:
      - main
    image: apache/kafka:3.7.0
    ports:
      - 9092:9092
      - 9093:9093
    volumes:
      - ./kafka/config:/mnt/shared/config
    environment:
      # Environment variables used by kafka scripts will be needed in case of File input.
      CLUSTER_ID: "4L6g3nShT-eMCtK--X86sw"
      # Set properties not provided in the file input
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"
      KAFKA_LISTENERS: "PLAINTEXT_HOST://:9092,SSL://:9093,CONTROLLER://:29093,PLAINTEXT://:19092"

  datasets-downloader:
    profiles:
      - datasets
    build: ./data
    volumes:
      - ./data:/data  # Mount host directory `./data` to container's `/data`
      - $HOME/.kaggle:/root/.kaggle:ro  # Mount Kaggle credentials as read-only
